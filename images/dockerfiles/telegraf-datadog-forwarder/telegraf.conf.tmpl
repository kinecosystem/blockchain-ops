# Telegraf configuration metric forwarding
# This configuration forwards metrics incoming on port 8086 to a graphite format on port 2003

# Global tags can be specified here in key="value" format.
[tags]

# Configuration for telegraf agent
[agent]
  # Default data collection interval for all inputs
  interval = "5s"
  # Rounds collection interval to 'interval'
  # ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  # Telegraf will cache metric_buffer_limit metrics for each output, and will
  # flush this buffer on a successful write.
  metric_buffer_limit = 10000

  # Collection jitter is used to jitter the collection by a random amount.
  # Each plugin will sleep for a random time within jitter before collecting.
  # This can be used to avoid many plugins querying things like sysfs at the
  # same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  # Default data flushing interval for all outputs. You should not set this below
  # interval. Maximum flush_interval will be flush_interval + flush_jitter
  flush_interval = "5s"
  # Jitter the flush interval by a random amount. This is primarily to avoid
  # large write spikes for users running a large number of telegraf instances.
  # ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  # Run telegraf in debug mode
  debug = false
  # Run telegraf in quiet mode
  quiet = false
  # Override default hostname, if empty use os.Hostname()
  hostname = ""


###############################################################################
#                                  OUTPUTS                                    #
###############################################################################

#[[outputs.graphite]]
#servers = ["metrics.kininfrastructure.com:2003"]
#prefix  = ""
#timeout = 10

# an putput for getting specific op-counts from one node's core (I chose kik)
[[outputs.datadog]]
  apikey = "${DATADOG_API_KEY}"
  namepass = ["core_metrics_stellar_operations_total"]
  [outputs.datadog.tagpass]
  node_name = ["kikkinfed"]
  [outputs.datadog.fieldpass]
  operation = ["payment","create-account"]

[[outputs.datadog]]
  # output the db metrics for the txhistory table from the cores. this inclues
  # operations like insert, delete and update (we only care for inserts, really).
  # with this configuration, all cores will report their local rate, which would allow us to
  # compare their performance.

  apikey = "${DATADOG_API_KEY}"
  fieldpass = ["0.95","0.75"]
  tagexclude = ["url","host"]
  namepass = ["core_metrics_stellar_database_operations_ms"]
  [outputs.datadog.tagpass]
    table = ["txhistory"]

[[outputs.datadog]]
  # Datadog API key
  apikey = "${DATADOG_API_KEY}"

  # drop a whole bunch of tags from various measurements (mem, netstat, disk, net) to save monies
  fielddrop = ["tcp_established", "tcp_syn_recv", "tcp_none", "udp_socket", "tcp_closing", "tcp_syn_sent", "tcp_fin_wait1", "tcp_close", "tcp_fin_wait2", "tcp_close_wait", "tcp_last_ack", "tcp_time_wait", "inodes_*", "mode", "icmp*", "udplite*", "ip_*", "udp_*", "swap_*","vmalloc_*","huge_page*","page_tables", "write_back*", "committed_as", "slab", "wired", "baseFee", "baseReserve"]

  namedrop = ["core_metrics*"] # dont send to dd, as there's so many of these. there are dedicaed outputs for these metrics
 
[[outputs.kinesis]] # sends the fed-network response-time stats to S3
   region = "us-east-1"
   streamname = "SLAMetricsStreamResponseTime"
   data_format = "influx"

   namepass = ["horizon_response_time"]
   fielddrop = ["stddev", "sum", "lower"] # we really just care for upper, mean
   tagexclude = ["metric_type"]
   [outputs.kinesis.tagpass]
    stellar_network = ["fed"] # only collect SLA for fed metrics

   [outputs.kinesis.partition]
     method = "measurement"

 #[[outputs.file]]
  ## Files to write to, "stdout" is a specially handled file.
  #files = ["/tmp/metrics.out", "stdout"]
  #data_format = "influx"

  #namepass = ["*"]
  #namepass = ["stellar_core_http*"]
  #fielddrop = ["tcp_established", "tcp_syn_recv"]

  #tagexclude = ["url", "stellar_network", "host"]
  #[outputs.file.tagpass]
  # node_name = ["d491"]

  #fieldpass = ["0.95","0.75"]
  #tagexclude = ["url","host"]
  #namepass = ["core_metrics_stellar_database_operations_ms"]
  #[outputs.file.tagpass]
    #table = ["txhistory"]
    #operation = ["insert"]

  #namedrop = ["core_metrics*"] # will drop all metrics from the core's /metrics endpoint

[[outputs.cloudwatch]]
   ## Amazon REGION
   region = "us-east-1"
   access_key = "${AWS_BI_ACCOUNT_ACCESS_KEY}"
   secret_key = "${AWS_BI_ACCOUNT_SECRET_KEY}"
   ## Namespace for the CloudWatch MetricDatums
   namespace = "KinEcosystem/Stats"
   namepass = ["stellar_core_http*"]
   fielddrop = ["version", "baseReserve", "baseFee"]
   tagexclude = ["url", "stellar_network", "host"]
   [outputs.cloudwatch.tagpass]
    node_name = ["kin-fed"] # only ship metrics for kin-fed node

[[outputs.kinesis]] # sends the fed-network ledger stats to S3
   region = "us-east-1"
   streamname = "SLAMetricsStreamLedger"
   data_format = "influx"

   namepass = ["stellar_core_http*"]
   fielddrop = ["baseReserve", "baseFee", "version"]
   tagexclude = ["url"]
   [outputs.kinesis.tagpass]
    stellar_network = ["fed"] # only collect SLA for fed metrics

  [outputs.kinesis.partition]
    method = "measurement"

###############################################################################
#                                  INPUTS                                     #
###############################################################################
[[inputs.http_listener]]
  ## Address and port to host HTTP listener on
  service_address = ":8086"

  ## maximum duration before timing out read of the request
  read_timeout = "5s"
  ## maximum duration before timing out write of the response
  write_timeout = "5s"

  ## Maximum allowed http request body size in bytes.
  ## 0 means to use the default of 536,870,912 bytes (500 mebibytes)
  max_body_size = 0

  ## Maximum line size allowed to be sent in bytes.
  ## 0 means to use the default of 65536 bytes (64 kibibytes)
  max_line_size = 0

# Statsd Server
[[inputs.statsd]]
  ## Protocol, must be "tcp", "udp4", "udp6" or "udp" (default=udp)
  protocol = "udp"

  ## MaxTCPConnection - applicable when protocol is set to tcp (default=250)
  max_tcp_connections = 250

  ## Enable TCP keep alive probes (default=false)
  tcp_keep_alive = false

  ## Specifies the keep-alive period for an active network connection.
  ## Only applies to TCP sockets and will be ignored if tcp_keep_alive is false.
  ## Defaults to the OS configuration.
  # tcp_keep_alive_period = "2h"

  ## Address and port to host UDP listener on
  service_address = ":8125"

  ## The following configuration options control when telegraf clears it's cache
  ## of previous values. If set to false, then telegraf will only clear it's
  ## cache when the daemon is restarted.
  ## Reset gauges every interval (default=true)
  delete_gauges = true
  ## Reset counters every interval (default=true)
  delete_counters = true
  ## Reset sets every interval (default=true)
  delete_sets = true
  ## Reset timings & histograms every interval (default=true)
  delete_timings = true

  ## Percentiles to calculate for timing & histogram stats
  percentiles = [90, 95, 99]

  ## separator to use between elements of a statsd metric
  metric_separator = "_"

  ## Parses tags in the datadog statsd format
  ## http://docs.datadoghq.com/guides/dogstatsd/
  parse_data_dog_tags = false

  ## Statsd data translation templates, more info can be read here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/TEMPLATE_PATTERN.md
  # templates = [
  #     "cpu.* measurement*"
  # ]

  ## Number of UDP messages allowed to queue up, once filled,
  ## the statsd server will start dropping packets
  allowed_pending_messages = 10000

  ## Number of timing/histogram values to track per-measurement in the
  ## calculation of percentiles. Raising this limit increases the accuracy
  ## of percentiles but also increases the memory usage and cpu time.
  percentile_limit = 1000

  ## Maximum socket buffer size in bytes, once the buffer fills up, metrics
  ## will start dropping.  Defaults to the OS default.
  # read_buffer_size = 65535

# vim: ft=toml
