# Telegraf configuration metric forwarding
# This configuration forwards metrics incoming on port 8086 to a graphite format on port 2003

# Global tags can be specified here in key="value" format.
[tags]

# Configuration for telegraf agent
[agent]
  # Default data collection interval for all inputs
  interval = "5s"
  # Rounds collection interval to 'interval'
  # ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  # Telegraf will cache metric_buffer_limit metrics for each output, and will
  # flush this buffer on a successful write.
  metric_buffer_limit = 10000

  # Collection jitter is used to jitter the collection by a random amount.
  # Each plugin will sleep for a random time within jitter before collecting.
  # This can be used to avoid many plugins querying things like sysfs at the
  # same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  # Default data flushing interval for all outputs. You should not set this below
  # interval. Maximum flush_interval will be flush_interval + flush_jitter
  flush_interval = "5s"
  # Jitter the flush interval by a random amount. This is primarily to avoid
  # large write spikes for users running a large number of telegraf instances.
  # ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  # Run telegraf in debug mode
  debug = false
  # Run telegraf in quiet mode
  quiet = false
  # Override default hostname, if empty use os.Hostname()
  hostname = ""


###############################################################################
#                                  OUTPUTS                                    #
###############################################################################

#[[outputs.graphite]]
#servers = ["metrics.kininfrastructure.com:2003"]
#prefix  = ""
#timeout = 10

[[outputs.datadog]]
  # Datadog API key
  apikey = "${DATADOG_API_KEY}"

[[outputs.kinesis]] # sends the fed-network response-time stats to S3
   region = "us-east-1"
   streamname = "SLAMetricsStreamResponseTime"
   data_format = "influx"

   namepass = ["horizon_response_time"]
   fielddrop = ["stddev", "sum", "lower", "upper"]
   tagexclude = ["metric_type"]
   [outputs.kinesis.tagpass]
    stellar_network = ["fed"] # only collect SLA for fed metrics

   [outputs.kinesis.partition]
     method = "measurement"

 #[[outputs.file]]
  ## Files to write to, "stdout" is a specially handled file.
  #files = ["/tmp/metrics.out"]

  ## Data format to output.
  ## Each data format has its own unique set of configuration options, read
  ## more about them here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md
  #data_format = "influx"

  #namepass = ["stellar_core_http*"]
  #fielddrop = ["version", "baseReserve", "baseFee"]
  #tagexclude = ["url", "stellar_network", "host"]
  #[outputs.file.tagpass]
  # node_name = ["d491"]


[[outputs.cloudwatch]]
   ## Amazon REGION
   region = "us-east-1"
   access_key = "${AWS_BI_ACCOUNT_ACCESS_KEY}"
   secret_key = "${AWS_BI_ACCOUNT_SECRET_KEY}"
   ## Namespace for the CloudWatch MetricDatums
   namespace = "KinEcosystem/Stats"
   namepass = ["stellar_core_http*"]
   fielddrop = ["version", "baseReserve", "baseFee"]
   tagexclude = ["url", "stellar_network", "host"]
   [outputs.cloudwatch.tagpass]
    node_name = ["d491"] # only ship metrics for d491 node. later replace with kin-fed

[[outputs.kinesis]] # sends the fed-network ledger stats to S3
   region = "us-east-1"
   streamname = "SLAMetricsStreamLedger"
   data_format = "influx"

   namepass = ["stellar_core_http*"]
   fielddrop = ["baseReserve", "baseFee", "version"]
   tagexclude = ["url"]
   [outputs.kinesis.tagpass]
    stellar_network = ["fed"] # only collect SLA for fed metrics

  [outputs.kinesis.partition]
    method = "measurement"

###############################################################################
#                                  INPUTS                                     #
###############################################################################
[[inputs.http_listener]]
  ## Address and port to host HTTP listener on
  service_address = ":8086"

  ## maximum duration before timing out read of the request
  read_timeout = "5s"
  ## maximum duration before timing out write of the response
  write_timeout = "5s"

  ## Maximum allowed http request body size in bytes.
  ## 0 means to use the default of 536,870,912 bytes (500 mebibytes)
  max_body_size = 0

  ## Maximum line size allowed to be sent in bytes.
  ## 0 means to use the default of 65536 bytes (64 kibibytes)
  max_line_size = 0

  # filter out core_metrics_* becuase there's just so many of them
  namepass = ["core_metrics_stellar_database_operations*"]
  #namedrop = ["core_metrics_*"] # will drop all metrics from the core


# Statsd Server
[[inputs.statsd]]
  ## Protocol, must be "tcp", "udp4", "udp6" or "udp" (default=udp)
  protocol = "udp"

  ## MaxTCPConnection - applicable when protocol is set to tcp (default=250)
  max_tcp_connections = 250

  ## Enable TCP keep alive probes (default=false)
  tcp_keep_alive = false

  ## Specifies the keep-alive period for an active network connection.
  ## Only applies to TCP sockets and will be ignored if tcp_keep_alive is false.
  ## Defaults to the OS configuration.
  # tcp_keep_alive_period = "2h"

  ## Address and port to host UDP listener on
  service_address = ":8125"

  ## The following configuration options control when telegraf clears it's cache
  ## of previous values. If set to false, then telegraf will only clear it's
  ## cache when the daemon is restarted.
  ## Reset gauges every interval (default=true)
  delete_gauges = true
  ## Reset counters every interval (default=true)
  delete_counters = true
  ## Reset sets every interval (default=true)
  delete_sets = true
  ## Reset timings & histograms every interval (default=true)
  delete_timings = true

  ## Percentiles to calculate for timing & histogram stats
  percentiles = [90, 95, 99]

  ## separator to use between elements of a statsd metric
  metric_separator = "_"

  ## Parses tags in the datadog statsd format
  ## http://docs.datadoghq.com/guides/dogstatsd/
  parse_data_dog_tags = false

  ## Statsd data translation templates, more info can be read here:
  ## https://github.com/influxdata/telegraf/blob/master/docs/TEMPLATE_PATTERN.md
  # templates = [
  #     "cpu.* measurement*"
  # ]

  ## Number of UDP messages allowed to queue up, once filled,
  ## the statsd server will start dropping packets
  allowed_pending_messages = 10000

  ## Number of timing/histogram values to track per-measurement in the
  ## calculation of percentiles. Raising this limit increases the accuracy
  ## of percentiles but also increases the memory usage and cpu time.
  percentile_limit = 1000

  ## Maximum socket buffer size in bytes, once the buffer fills up, metrics
  ## will start dropping.  Defaults to the OS default.
  # read_buffer_size = 65535

# vim: ft=toml
